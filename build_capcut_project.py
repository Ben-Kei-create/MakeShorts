import json, os, glob
from pathlib import Path
from natsort import natsorted
import argparse

def parse_args():
    p = argparse.ArgumentParser()
    p.add_argument("--scripts-dir", default="zap1/outputs/scripts")
    p.add_argument("--images-root", default="zap1/images")
    p.add_argument("--voice-root",  default="zap1/voice")
    p.add_argument("--bgm-root",    default="zap1/bgm")
    p.add_argument("--out-ccproj",  default="zap1/output/walt_capcut.ccproj")
    p.add_argument("--out-csv",     default="zap1/output/shotlist.csv")
    return p.parse_args()

# æ—¢å­˜ã®å®šæ•°ã‚’å¼•æ•°ã§ä¸Šæ›¸ã
args = parse_args()
SCRIPTS_DIR = args.scripts_dir
IMAGES_ROOT = args.images_root
VOICE_ROOT  = args.voice_root
BGM_ROOT    = args.bgm_root
OUT_CCPROJ  = args.out_ccproj
OUT_CSV     = args.out_csv

FPS = 30
IMG_FIT = "cover"      # "cover" or "contain"ï¼ˆãƒ¬ã‚¿ãƒ¼ãƒœãƒƒã‚¯ã‚¹å›é¿æ¨å¥¨ã¯"cover"ï¼‰
IMG_XFADE_SEC = 0.5     # ç”»åƒã‚¯ãƒªãƒƒãƒ—é–“ã®å¾®ãƒ•ã‚§ãƒ¼ãƒ‰
AUDIO_FADE_SEC = 1.5    # BGMã®æ›²é–“ã‚¯ãƒ­ã‚¹ãƒ•ã‚§ãƒ¼ãƒ‰
DUCKING_DB = -12        # ãƒœã‚¤ã‚¹ä¸‹ã§BGMã‚’-12dB
PADDING_LEAD = 0.0      # å…ˆé ­ä½™ç™½(ç§’)
# ============================================================

def read_chapter_batches():
    files = natsorted(glob.glob(os.path.join(SCRIPTS_DIR, "chapter_*.json")))
    chapters = []
    for f in files:
        with open(f, "r", encoding="utf-8") as rf:
            data = json.load(rf)
            chapters.append(data)
    # chapter_indexã§ã‚½ãƒ¼ãƒˆï¼ˆå®‰å…¨ç­–ï¼‰
    chapters = sorted(chapters, key=lambda x: x.get("chapter_index", 0))
    return chapters

def sec2frame(s): return int(round(s * FPS))

def ensure_dirs():
    Path(os.path.dirname(OUT_CCPROJ)).mkdir(parents=True, exist_ok=True)

def motion_by_emotion(level:int, index:int):
    """emotion_levelã«å¿œã˜ãŸKen Burnsãƒ—ãƒªã‚»ãƒƒãƒˆã‚’è¿”ã™"""
    if level <= 2:
        base = "kenburns-zoom-out"
    elif level <= 4:
        base = "kenburns-pan-right"
    elif level <= 6:
        base = "kenburns-zoom-in"
    elif level <= 8:
        base = "kenburns-pan-left"
    else:
        base = "kenburns-zoom-in"
    # è»½ã„ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ä»˜ã‘
    if index % 2 == 0 and "zoom" in base:
        base += "-slow"
    return base

def make_timeline(chapters):
    """
    å†…éƒ¨çš„ãªã€æ±ç”¨CapCuté¢¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆJSONã€ã‚’æ§‹ç¯‰ã€‚
    â€»CapCutã¯ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã‚¹ã‚­ãƒ¼ãƒãŒå¤‰ã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€
      ã€Œãƒ‘ã‚¹ãƒ»é–‹å§‹ç§’ãƒ»é•·ã•ãƒ»ãƒˆãƒ©ãƒƒã‚¯æ§‹é€ ã€ã‚’ç´ ç›´ã«æŒã¤æœ€å°æ§‹æˆã‚’å‡ºåŠ›ã€‚
      èª­ã¿è¾¼ã¿æ™‚ã«ã‚ºãƒ¬ãŸã‚‰ã€ã“ã®JSONã‚’åŸºã«CapCutã§æ‰‹ä¿®æ­£ã—ã‚„ã™ã„ã€‚
    """
    t = {
        "meta": {"name": "Walt Documentary Auto Timeline", "fps": FPS, "resolution": "1920x1080"},
        "tracks": [
            {"type": "video", "clips": []},   # ç”»åƒä¸¦ã¹
            {"type": "audio", "role": "voice", "clips": []},   # ç« ãƒœã‚¤ã‚¹
            {"type": "audio", "role": "bgm", "clips": []},     # BGM
            {"type": "subtitles", "clips": []}                 # äºˆå‚™ï¼ˆä»Šå›ã¯æœªä½¿ç”¨ï¼‰
        ],
        "mix": {
            "ducking": {"enable": True, "under_role": "voice", "target_role": "bgm", "gain_db": DUCKING_DB}
        }
    }

    # === æ˜ åƒãƒ»ãƒœã‚¤ã‚¹ ===
    global_time = PADDING_LEAD
    shotlist_rows = []

    video_track = t["tracks"][0]["clips"]
    voice_track = t["tracks"][1]["clips"]

    for chap in chapters:
        chap_id = chap["id"]
        dur = float(chap.get("duration_sec", 0) or 0)
        if dur <= 0: 
            continue

        # ç”»åƒ3æšãŒåŸºæœ¬ï¼ˆä¸è¶³ã¯ç« å†…ã§ç¹°ã‚Šè¿”ã—ï¼‰
        stills = chap.get("still_prompts", [])  # ä¸­èº«ã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã ãŒã€å®Ÿãƒ•ã‚¡ã‚¤ãƒ«ã¯ images/<id> å†…ã®å®Ÿä½“ã‚’ä½¿ã†
        # å®Ÿãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ‹¾ã†ï¼ˆ*.png, *.jpgï¼‰
        img_files = natsorted(
            glob.glob(os.path.join(IMAGES_ROOT, chap_id, "*.png")) +
            glob.glob(os.path.join(IMAGES_ROOT, chap_id, "*.jpg")) +
            glob.glob(os.path.join(IMAGES_ROOT, chap_id, "*.jpeg"))
        )
        if not img_files:
            # ç”»åƒãŒæœªç”Ÿæˆã§ã‚‚ã€ç©ºç™½ãƒ•ãƒ¬ãƒ¼ãƒ ã«ãªã‚‰ãªã„ã‚ˆã†ã«ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€æ‰±ã„
            img_files = []

        # 3åˆ†å‰²
        per = dur / max(1, max(3, len(img_files)))  # ç”»åƒãŒå¤šã‘ã‚Œã°å‡ç­‰åˆ†å‰²
        frames = []
        # ä¸¦ã¹ã‚‹å¯¾è±¡
        targets = img_files if img_files else []
        if img_files and len(img_files) < 3:
            # 2ä»¥ä¸‹ãªã‚‰é‡è¤‡ä½¿ç”¨
            while len(targets) < 3:
                targets += img_files
            targets = targets[:3]
        elif not img_files:
            # æœ¬å½“ã«ä½•ã‚‚ç„¡ã„å ´åˆã¯ãƒ€ãƒŸãƒ¼ã‚¨ãƒ³ãƒˆãƒªï¼ˆCapCutä¸Šã§å¾Œå·®ã—æ›¿ãˆï¼‰
            targets = [f"[MISSING:{chap_id}:img{i+1}]" for i in range(3)]

        start = global_time
        for i, path in enumerate(targets):
            length = per
            if i == len(targets)-1:
                # ç«¯æ•°ã¯æœ€å¾Œã«å¸å
                length = (PADDING_LEAD + sum([c.get('duration_sec',0) for c in chapters[:chapters.index(chap)]]) 
                          + dur) - (start)

            # æ„Ÿæƒ…ãƒ¬ãƒ™ãƒ«ã«å¿œã˜ãŸãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é©ç”¨
            emotion_level = chap.get("emotion_level", 5)  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ5
            motion = motion_by_emotion(emotion_level, i)
            video_track.append({
                "path": path.replace("\\\\", "/"),
                "start": round(start, 3),
                "duration": round(length, 3),
                "fit": IMG_FIT,
                "transition_in": {"type": "fade", "duration": IMG_XFADE_SEC} if i>0 else None,
                "transition_out": {"type": "fade", "duration": IMG_XFADE_SEC} if i < len(targets)-1 else None,
                "motion": {"preset": motion, "emotion_level": emotion_level}
            })
            shotlist_rows.append([chap["chapter_index"], chap_id, path, round(start,3), round(length,3)])
            start += length

        # ãƒœã‚¤ã‚¹
        voice_path = os.path.join(VOICE_ROOT, f"{chap_id}.wav")
        if os.path.exists(voice_path):
            voice_track.append({
                "path": voice_path.replace("\\\\", "/"),
                "start": round(global_time, 3),
                "duration": round(dur, 3),
                "fade_in": AUDIO_FADE_SEC/2,
                "fade_out": AUDIO_FADE_SEC/2
            })

        global_time += dur

    # === BGMï¼ˆãƒ•ã‚©ãƒ«ãƒ€å†…ã‚’é †ã«æ•·ãè©°ã‚ãƒ»æ›²é–“ã‚¯ãƒ­ã‚¹ãƒ•ã‚§ãƒ¼ãƒ‰ï¼‰ ===
    bgm_files = natsorted(
        glob.glob(os.path.join(BGM_ROOT, "*.mp3")) +
        glob.glob(os.path.join(BGM_ROOT, "*.wav")) +
        glob.glob(os.path.join(BGM_ROOT, "*.m4a")) +
        glob.glob(os.path.join(BGM_ROOT, "*.flac"))
    )
    total_len = PADDING_LEAD + sum(float(c.get("duration_sec",0) or 0) for c in chapters)
    bgm_track = t["tracks"][2]["clips"]

    tpos = 0.0
    idx = 0
    while tpos < total_len and bgm_files:
        fpath = bgm_files[idx % len(bgm_files)]
        # ä»®ï¼šæ›²é•·ã¯æœªçŸ¥â†’CapCutå´ã§æ›²æœ«ã¾ã§è‡ªå‹•å»¶é•·ã—ã¦ãã‚Œã‚‹ã‚±ãƒ¼ã‚¹å¤šã—ã€‚
        # ã“ã“ã§ã¯ã€Œãƒãƒ£ãƒ—ã‚¿ãƒ¼ã®å¢ƒç›®ã«åˆã‚ã›ãšã€å…¨ä½“ã‚’é †é€ã‚Šã€ã§ç½®ãã€‚
        # ï¼ˆå¿…è¦ãªã‚‰ffprobeç­‰ã§å®Ÿé•·å–å¾—â†’æ˜ç¤ºé•·ã«ã—ã¦ã‚‚OKï¼‰
        clip_len = min(190.0, total_len - tpos)  # ã ã„ãŸã„3åˆ†å¼±ç›¸å½“ãƒ»æœ«å°¾ã§æ‰“ã¡åˆ‡ã‚Š
        bgm_track.append({
            "path": fpath.replace("\\\\", "/"),
            "start": round(max(0, tpos - (idx>0)*AUDIO_FADE_SEC), 3),
            "duration": round(clip_len + (idx>0)*AUDIO_FADE_SEC, 3),
            "fade_in": AUDIO_FADE_SEC if idx>0 else 0.5,
            "fade_out": AUDIO_FADE_SEC
        })
        tpos += clip_len
        idx += 1

    return t, shotlist_rows

def write_outputs(project_json, shotlist_rows):
    ensure_dirs()
    with open(OUT_CCPROJ, "w", encoding="utf-8") as wf:
        json.dump(project_json, wf, ensure_ascii=False, indent=2)

    # å‚ç…§ç”¨ã‚·ãƒ§ãƒƒãƒˆãƒªã‚¹ãƒˆ
    import csv
    with open(OUT_CSV, "w", encoding="utf-8", newline="") as cf:
        w = csv.writer(cf)
        w.writerow(["chapter_index","chapter_id","image_path","start_sec","duration_sec"])
        w.writerows(shotlist_rows)

from shutil import copyfile

def copy_to_capcut_projects(out_ccproj_path: str, person_name: str):
    """ç”Ÿæˆã•ã‚ŒãŸ.ccprojã‚’CapCutã®ãƒ­ãƒ¼ã‚«ãƒ«ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ•ã‚©ãƒ«ãƒ€ã«ã‚³ãƒ”ãƒ¼ã™ã‚‹"""
    try:
        # CapCutã®ãƒ­ãƒ¼ã‚«ãƒ«ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ•ã‚©ãƒ«ãƒ€
        base_dir = "/Users/fumiaki/Movies/CapCut/User Data/projects"
        project_dir = os.path.join(base_dir, person_name.replace(" ", "_"))
        os.makedirs(project_dir, exist_ok=True)

        dest_path = os.path.join(project_dir, f"{person_name.replace(' ', '_')}.ccproj")
        copyfile(out_ccproj_path, dest_path)

        print(f"ğŸ“¦ CapCutãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ•ã‚©ãƒ«ãƒ€ã«ã‚³ãƒ”ãƒ¼å®Œäº†: {dest_path}")
        print("   â†’ CapCutã‚’é–‹ã‘ã°ãƒ›ãƒ¼ãƒ ç”»é¢ã«è‡ªå‹•ã§è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
    except Exception as e:
        print(f"âš ï¸ CapCutãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ•ã‚©ãƒ«ãƒ€ã¸ã®ã‚³ãƒ”ãƒ¼ã«å¤±æ•—: {e}")

def main():
    chapters = read_chapter_batches()
    project_json, shotlist_rows = make_timeline(chapters)
    write_outputs(project_json, shotlist_rows)
    print(f"âœ… CapCutãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆJSONã‚’æ›¸ãå‡ºã—: {OUT_CCPROJ}")
    print(f"âœ… ã‚·ãƒ§ãƒƒãƒˆãƒªã‚¹ãƒˆCSVã‚’æ›¸ãå‡ºã—:      {OUT_CSV}")
    print("   â†’ CapCutã§ .ccproj ã‚’é–‹ã‘ã°ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ãŒå±•é–‹ã•ã‚Œã¾ã™ã€‚")

    # CapCutãƒ­ãƒ¼ã‚«ãƒ«ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¸ã®è‡ªå‹•ã‚³ãƒ”ãƒ¼
    try:
        # äººåã‚’æŠ½å‡ºï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åãªã©ã‹ã‚‰åˆ¤å®šï¼‰
        person_name = Path(OUT_CCPROJ).stem.split("_capcut")[0] # _capcutã¾ã§å«ã‚ã¦split
        copy_to_capcut_projects(OUT_CCPROJ, person_name)
    except Exception as e:
        print(f"âš ï¸ è‡ªå‹•ã‚³ãƒ”ãƒ¼ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

if __name__ == "__main__":
    main()
